{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18350,"status":"ok","timestamp":1747837873602,"user":{"displayName":"Romain Letellier","userId":"15950151700417960037"},"user_tz":-120},"id":"GFrxig37B6eH","outputId":"10d46af6-c17c-45df-9105-9dab3c7386ac"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":93612,"status":"ok","timestamp":1747400845574,"user":{"displayName":"Romain Letellier","userId":"15950151700417960037"},"user_tz":-120},"id":"BjK3srDo6CnX","outputId":"f9ee975b-9609-4845-e1a2-69df1971a780"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting thop\n","  Downloading thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\n","Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from thop) (2.6.0+cu124)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->thop) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (4.13.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->thop) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->thop) (2025.3.2)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->thop)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->thop)\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->thop)\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->thop)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->thop)\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->thop)\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch->thop)\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->thop)\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->thop)\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->thop)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->thop) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->thop) (3.0.2)\n","Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n","Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m87.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m72.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m61.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, thop\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 thop-0.1.1.post2209072238\n"]}],"source":["pip install thop"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CAW73cwb3IoQ"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from thop import profile\n","import os"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TaEOVb5ftJZ1"},"outputs":[],"source":["def print_shapes(x, stage):\n","    print(f\"Stage: {stage} | Shape: {x.shape} | Channels: {x.shape[1]}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GJ2zTQkV3RJ3"},"outputs":[],"source":["class ResidualBlock(nn.Module):\n","    def __init__(self, channels):\n","        super().__init__()\n","        self.conv1 = nn.Sequential(\n","            nn.Conv2d(channels, channels, kernel_size=3, padding=1, bias=False),\n","            nn.BatchNorm2d(channels),\n","            nn.ReLU(inplace=True)\n","        )\n","        self.conv2 = nn.Sequential(\n","            nn.Conv2d(channels, channels, kernel_size=3, padding=1, bias=False),\n","            nn.BatchNorm2d(channels)\n","        )\n","        self.relu = nn.ReLU(inplace=True)\n","\n","    def forward(self, x):\n","        identity = x\n","        out = self.conv1(x)\n","        out = self.conv2(out)\n","        out += identity\n","        return self.relu(out)\n","\n","class DoubleConv(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super().__init__()\n","        self.preconv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n","        self.res1 = ResidualBlock(out_channels)\n","        self.res2 = ResidualBlock(out_channels)\n","\n","    def forward(self, x):\n","        identity = self.preconv(x)\n","        out = self.res1(identity)\n","        out = self.res2(out)\n","        return out + identity\n","\n","class DoubleConvUp(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super().__init__()\n","        self.block = nn.Sequential(\n","            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, bias=False),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, bias=False),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True)\n","        )\n","\n","    def forward(self, x):\n","        return self.block(x)\n","\n","\n","class Down(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super().__init__()\n","        self.maxpool_conv = nn.Sequential(\n","            nn.AvgPool2d(kernel_size=2),\n","            DoubleConv(in_channels, out_channels)\n","        )\n","\n","    def forward(self, x):\n","        return self.maxpool_conv(x)\n","\n","class Up(nn.Module):\n","    def __init__(self, up_channels, skip_channels, out_channels, bilinear=True):\n","        super().__init__()\n","\n","        if bilinear:\n","            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n","        else:\n","            self.up = nn.ConvTranspose2d(up_channels, up_channels, kernel_size=2, stride=2)\n","\n","        self.reduce_channels = nn.Conv2d(up_channels + skip_channels, out_channels, kernel_size=1)\n","        self.conv = DoubleConv(out_channels, out_channels)\n","\n","    def forward(self, x1, x2):\n","        x1 = self.up(x1)\n","        diffY = x2.size()[2] - x1.size()[2]\n","        diffX = x2.size()[3] - x1.size()[3]\n","        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n","                        diffY // 2, diffY - diffY // 2])\n","        x = torch.cat([x1, x2], dim=1)\n","        x = self.reduce_channels(x)\n","        return self.conv(x)\n","\n","class OutConv(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super(OutConv, self).__init__()\n","        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n","\n","    def forward(self, x):\n","        return self.conv(x)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LHAmRXZk50Td"},"outputs":[],"source":["class UNet(nn.Module):\n","    def __init__(self, n_channels, bilinear=False):\n","        super(UNet, self).__init__()\n","        self.n_channels = n_channels\n","        self.bilinear = bilinear\n","\n","        self.inc = DoubleConv(n_channels, 16)\n","        self.down1 = (Down(16, 32))\n","        self.down2 = (Down(32, 64))\n","        self.down3 = (Down(64, 128))\n","        factor = 2 if bilinear else 1\n","        self.up1 = Up(128, 64, 64, bilinear)\n","        self.up2 = Up(64, 32, 32, bilinear)\n","        self.up3 = Up(32, 16, 16, bilinear)\n","        self.outc = (OutConv(16, 1))\n","\n","    def forward(self, x):\n","        x1 = model.inc(x)\n","        x2 = model.down1(x1)\n","        x3 = model.down2(x2)\n","        x4 = model.down3(x3)\n","        x = model.up1(x4, x3)\n","        x = model.up2(x, x2)\n","        x = model.up3(x, x1)\n","        x = model.outc(x)\n","        return x\n","\n","    def use_checkpointing(self):\n","        self.inc = torch.utils.checkpoint(self.inc)\n","        self.down1 = torch.utils.checkpoint(self.down1)\n","        self.down2 = torch.utils.checkpoint(self.down2)\n","        self.down3 = torch.utils.checkpoint(self.down3)\n","        self.down4 = torch.utils.checkpoint(self.down4)\n","        self.up1 = torch.utils.checkpoint(self.up1)\n","        self.up2 = torch.utils.checkpoint(self.up2)\n","        self.up3 = torch.utils.checkpoint(self.up3)\n","        self.up4 = torch.utils.checkpoint(self.up4)\n","        self.outc = torch.utils.checkpoint(self.outc)"]},{"cell_type":"markdown","metadata":{"id":"hAeRFEjiOUA3"},"source":["Read the Data"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"yD0UZQJxNNGt","executionInfo":{"status":"ok","timestamp":1747837914000,"user_tz":-120,"elapsed":1020,"user":{"displayName":"Romain Letellier","userId":"15950151700417960037"}}},"outputs":[],"source":["from osgeo import gdal\n","\n","def read_modis_var_from_hdf_gdal(filepath, var_name):\n","    dataset = gdal.Open(filepath)\n","    if dataset is None:\n","        raise ValueError(f\"Impossible d'ouvrir {filepath}\")\n","\n","    subdatasets = dataset.GetSubDatasets()\n","    print(\"\\n\".join(f\"{name} | {desc}\" for name, desc in subdatasets))\n","    for name, desc in subdatasets:\n","        if var_name in name or var_name in desc:\n","            ds = gdal.Open(name)\n","            array = ds.ReadAsArray()\n","            return array\n","    raise ValueError(f\"Variable {var_name} non trouvée dans {filepath}\")"]},{"cell_type":"markdown","source":[],"metadata":{"id":"0QBxAcvHRwn1"}},{"cell_type":"code","execution_count":6,"metadata":{"id":"oOhyFTQgPJ5d","colab":{"base_uri":"https://localhost:8080/","height":269},"executionInfo":{"status":"error","timestamp":1747838319727,"user_tz":-120,"elapsed":263,"user":{"displayName":"Romain Letellier","userId":"15950151700417960037"}},"outputId":"d9aa1452-a5d6-47ce-9335-8f0cf75dea1c"},"outputs":[{"output_type":"error","ename":"ValueError","evalue":"Impossible d'ouvrir /content/drive/MyDrive/MLA/Project/data/hdf_files/MOD09GQ.A2017002.h18v04.061.2021363134842.hdf","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-ad63670bb197>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mread_modis_var_from_hdf_gdal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/MLA/Project/data/hdf_files/MOD09GQ.A2017002.h18v04.061.2021363134842.hdf\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"QC_250m_1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-2-0658d6e18df0>\u001b[0m in \u001b[0;36mread_modis_var_from_hdf_gdal\u001b[0;34m(filepath, var_name)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgdal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Impossible d'ouvrir {filepath}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0msubdatasets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetSubDatasets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Impossible d'ouvrir /content/drive/MyDrive/MLA/Project/data/hdf_files/MOD09GQ.A2017002.h18v04.061.2021363134842.hdf"]}],"source":["read_modis_var_from_hdf_gdal(\"/content/drive/MyDrive/MLA/Project/data/hdf_files/MOD09GQ.A2017002.h18v04.061.2021363134842.hdf\",\"QC_250m_1\")"]},{"cell_type":"markdown","metadata":{"id":"xTyOci92OWOC"},"source":["Converting them into Tensors"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20,"status":"ok","timestamp":1747400853601,"user":{"displayName":"Romain Letellier","userId":"15950151700417960037"},"user_tz":-120},"id":"nOelym8Da9GT","outputId":"6046444e-9acb-4038-9e5c-4a1db325ba7b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Nombre de fenêtres valides : 256\n"]}],"source":["import numpy as np\n","\n","def extract_valid_windows(array, window_size=32, target_value=4096):\n","    no_cloud_windows = []\n","    h, w = array.shape\n","\n","    for i in range(0, h - window_size + 1, window_size):\n","        for j in range(0, w - window_size + 1, window_size):\n","            window = array[i:i+window_size, j:j+window_size]\n","\n","            if np.all(window == target_value):\n","                no_cloud_windows.append(window)\n","\n","    return no_cloud_windows\n","\n","array = np.full((512, 512), 4096, dtype=np.uint16)\n","\n","no_cloud_windows = extract_valid_windows(array, window_size=32, target_value=4096)\n","\n","print(f\"Nombre de fenêtres valides : {len(no_cloud_windows)}\")\n"]},{"cell_type":"markdown","metadata":{"id":"frcAjGMUfn3P"},"source":["**Dataset TIFF definition**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o6QxmjsY3EAz"},"outputs":[],"source":["import pandas as pd\n","from torch.utils.data import Dataset\n","import torchvision.transforms as T\n","import tifffile"]},{"cell_type":"code","source":["def normalize(img):\n","    mean = img.mean()\n","    std = img.std()\n","    return (img - mean) / std"],"metadata":{"id":"_Z_QcH11M0yo"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5GXFGqJBfnaV"},"outputs":[],"source":["class LSTNDVIDataset(Dataset):\n","    def __init__(self, csv_file, transform=None, base_dir=\"/content/drive/MyDrive/MLA/Project\"):\n","        self.data = pd.read_csv(csv_file)\n","        self.transform = transform\n","        self.base_dir = base_dir\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        lst_path = os.path.join(self.base_dir, self.data.iloc[idx, 1])\n","        ndvi_path = os.path.join(self.base_dir, self.data.iloc[idx, 2])\n","\n","        lst = tifffile.imread(lst_path)\n","        ndvi = tifffile.imread(ndvi_path)\n","\n","        lst = torch.tensor(lst, dtype=torch.float32).unsqueeze(0)\n","        ndvi = torch.tensor(ndvi, dtype=torch.float32).unsqueeze(0)\n","\n","        lst = normalize(lst)\n","        ndvi = normalize(ndvi)\n","\n","        return ndvi, lst"]},{"cell_type":"markdown","metadata":{"id":"bnQ0ISyreEF6"},"source":["**Running the U-Net**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W0ZBsRAliP_G"},"outputs":[],"source":["def degrade_image(img, scale=0.5):\n","    h, w = img.shape[2:]\n","    new_h, new_w = int(h * scale), int(w * scale)\n","    lowres = F.interpolate(img, size=(new_h, new_w), mode='bilinear', align_corners=False)\n","    upscaled = F.interpolate(lowres, size=(h, w), mode='bilinear', align_corners=False)\n","    return upscaled"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NmRoGqGGeC5V"},"outputs":[],"source":["from torch.utils.data import DataLoader\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","model = UNet(n_channels=2, bilinear=True)\n","model = model.to(\"cpu\")\n","\n","ndvi = torch.randn(1, 4, 256, 256)\n","lst = torch.randn(1, 4, 256, 256)\n","input = torch.cat([ndvi, lst], dim=1)\n","\n","criterion = nn.MSELoss()\n","optimizer = optim.Adam(model.parameters(), lr=1e-4)\n","scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","dataset = LSTNDVIDataset(\"/content/drive/MyDrive/MLA/Project/data/pairs_day.csv\")\n","loader = DataLoader(dataset, batch_size=4, shuffle=True)\n","\n","n_epochs = 1"]},{"cell_type":"code","source":["def sobel_gradient(x):\n","    # x : [B, C, H, W]\n","    sobel_x = torch.tensor([[[-1, 0, 1],\n","                             [-2, 0, 2],\n","                             [-1, 0, 1]]], dtype=torch.float32, device=x.device).unsqueeze(0)\n","    sobel_y = torch.tensor([[[-1, -2, -1],\n","                             [ 0,  0,  0],\n","                             [ 1,  2,  1]]], dtype=torch.float32, device=x.device).unsqueeze(0)\n","\n","    # Appliquer sur chaque canal\n","    gradients_x = F.conv2d(x, sobel_x.expand(x.shape[1], 1, 3, 3), padding=1, groups=x.shape[1])\n","    gradients_y = F.conv2d(x, sobel_y.expand(x.shape[1], 1, 3, 3), padding=1, groups=x.shape[1])\n","\n","    return gradients_x, gradients_y"],"metadata":{"id":"dor_VAi8QbMN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for epoch in range(n_epochs):\n","    model.train()\n","    # i = 0\n","    for ndvi, lst in loader:\n","        # if i == 100:\n","        #     break\n","        # i += 1\n","        target_size = ndvi.shape[2:]\n","\n","        if ndvi.dim() == 3:\n","            ndvi = ndvi.unsqueeze(0)\n","        if lst.dim() == 3:\n","            lst = lst.unsqueeze(0)\n","\n","        lst = F.interpolate(\n","            lst,\n","            size=ndvi.shape[2:],\n","            mode='bilinear',\n","            align_corners=False\n","        )\n","\n","        ndvi, lst = ndvi.to(device), lst.to(device)\n","        input = torch.cat([ndvi, lst], dim=1)\n","        output = model(input)\n","\n","        ndvi_grad_x, ndvi_grad_y = sobel_gradient(ndvi)\n","        output_grad_x, output_grad_y = sobel_gradient(output)\n","\n","        ndvi_grad = torch.sqrt(ndvi_grad_x**2 + ndvi_grad_y**2)\n","        output_grad = torch.sqrt(output_grad_x**2 + output_grad_y**2)\n","\n","        loss = criterion(output, lst)\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        scheduler.step()\n","\n","\n","    print(f\"Epoch {epoch+1}: Loss = {loss.item():.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":365},"id":"nqmbuIpZ21tM","executionInfo":{"status":"error","timestamp":1747401006024,"user_tz":-120,"elapsed":11366,"user":{"displayName":"Romain Letellier","userId":"15950151700417960037"}},"outputId":"bb229f2c-8580-4be8-b4e8-c0380ccf4b07"},"execution_count":null,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-8f2ffd5a82e1>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mndvi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mndvi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mndvi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlst\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mndvi_grad_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndvi_grad_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msobel_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndvi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-6-3b2ae36e13cc>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdown1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mx3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdown2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-5-00e1057b8010>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0midentity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mres1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mres2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    547\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m             )\n\u001b[0;32m--> 549\u001b[0;31m         return F.conv2d(\n\u001b[0m\u001b[1;32m    550\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m         )\n","\u001b[0;31mRuntimeError\u001b[0m: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qj-o18oehJQx"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","from torchvision.transforms.functional import to_pil_image\n","\n","\n","model.eval()\n","\n","n_examples = 5\n","displayed = 0\n","\n","\n","with torch.no_grad():\n","    for data in loader:\n","        ndvi, lst = data[0].to(\"cpu\"),  data[1].to(\"cpu\")\n","\n","        if ndvi.dim() == 3:\n","            ndvi = ndvi.unsqueeze(0)\n","        if lst.dim() == 3:\n","            lst = lst.unsqueeze(0)\n","\n","        lst = F.interpolate(lst, size=ndvi.shape[2:], mode='bilinear', align_corners=False)\n","        input = torch.cat([ndvi, lst], dim=1)\n","        pred = model(input)\n","\n","        loss = F.mse_loss(pred, lst)\n","        print(\"MSE sur la sortie du modèle vs LST réelle :\", loss.item())\n","\n","        batch_size = ndvi.shape[0]\n","        for b in range(batch_size):\n","            if displayed >= n_examples:\n","                break\n","\n","            fig, axs = plt.subplots(1, 3, figsize=(12, 4))\n","            axs[0].imshow(ndvi[b, 0], cmap='viridis')\n","            axs[0].set_title(\"NDVI\")\n","            axs[1].imshow(lst[b, 0], cmap='inferno')\n","            axs[1].set_title(\"LST Réelle\")\n","            axs[2].imshow(pred[b, 0], cmap='inferno')\n","            axs[2].set_title(\"LST Prédite\")\n","\n","            for ax in axs:\n","                ax.axis(\"off\")\n","            plt.tight_layout()\n","            plt.show()\n","\n","            displayed += 1\n","\n","        if displayed >= n_examples:\n","            break\n","\n","\n","for data in loader:\n","    ndvi, lst = data[0].to(device),  data[1].to(device)\n","\n","    if ndvi.dim() == 3:\n","        ndvi = ndvi.unsqueeze(0)\n","    if lst.dim() == 3:\n","        lst = lst.unsqueeze(0)\n","\n","    lst = F.interpolate(lst, size=ndvi.shape[2:], mode='bilinear', align_corners=False)\n","    input = torch.cat([ndvi, lst], dim=1)\n","    macs, params = profile(model, inputs=(input[0].unsqueeze(0),))\n","    break\n","\n","print(f\"Nombre de MACs : {macs:,}\")\n","print(f\"Nombre de paramètres : {params:,}\")\n"]},{"cell_type":"code","source":["i = 0\n","\n","for ndvi, lst in loader:\n","    mean = 0.\n","    var = 0.\n","    nb_pixels = 0\n","\n","    if i == 100:\n","        break\n","    batch = ndvi\n","    batch = batch.to(torch.float32)\n","\n","    n = batch.numel()\n","\n","    mean += batch.sum().item()\n","    var += (batch ** 2).sum().item()\n","    nb_pixels += n\n","    i += 1\n","\n","    mean /= nb_pixels\n","    var = var / nb_pixels - mean ** 2\n","    std = var ** 0.5\n","\n","    print(f\"Mean: {mean:.4f}\")\n","    print(f\"Std : {std:.4f}\")\n"],"metadata":{"id":"jRQlkjLj1_hu"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}